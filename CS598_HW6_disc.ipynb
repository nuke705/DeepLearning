{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "#import h5py\n",
    "import time\n",
    "import copy\n",
    "from random import randint\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32, scale=(0.7, 1.0), ratio=(1.0,1.0)),\n",
    "    transforms.ColorJitter(\n",
    "            brightness=0.1*torch.randn(1),\n",
    "            contrast=0.1*torch.randn(1),\n",
    "            saturation=0.1*torch.randn(1),\n",
    "            hue=0.1*torch.randn(1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.CenterCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0)\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3  ,196, 3,1,1)\n",
    "        self.conv2 = nn.Conv2d(196,196, 3,2,1)\n",
    "        self.conv3 = nn.Conv2d(196,196, 3,1,1)\n",
    "        self.conv4 = nn.Conv2d(196,196, 3,2,1)\n",
    "        self.conv5 = nn.Conv2d(196,196, 3,1,1)\n",
    "        self.conv6 = nn.Conv2d(196,196, 3,1,1)\n",
    "        self.conv7 = nn.Conv2d(196,196, 3,1,1)\n",
    "        self.conv8 = nn.Conv2d(196,196, 3,2,1)\n",
    "        \n",
    "        self.ln1 = nn.LayerNorm((196,32,32))\n",
    "        self.ln2 = nn.LayerNorm((196,16,16))\n",
    "        self.ln3 = nn.LayerNorm((196,16,16))\n",
    "        self.ln4 = nn.LayerNorm((196,8,8))\n",
    "        self.ln5 = nn.LayerNorm((196,8,8))\n",
    "        self.ln6 = nn.LayerNorm((196,8,8))\n",
    "        self.ln7 = nn.LayerNorm((196,8,8))\n",
    "        self.ln8 = nn.LayerNorm((196,4,4))\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.pool = nn.MaxPool2d(4,4)           # 4*4\n",
    "        self.lkrl = nn.LeakyReLU()\n",
    "        self.fc1 = nn.Linear(196, 1)            # 1     critic output\n",
    "        self.fc10 = nn.Linear(196, 10)          # 10    auxiliary \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #layer1\n",
    "        x = self.conv1(x)\n",
    "        x = self.ln1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.ln2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "       \n",
    "        x = self.conv3(x)\n",
    "        x = self.ln3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.ln4(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = self.ln5(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        x = self.conv6(x)\n",
    "        x = self.ln6(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        x = self.conv7(x)\n",
    "        x = self.ln7(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        x = self.conv8(x)\n",
    "        x = self.ln8(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        x1 = x.view(-1, 196)\n",
    "        critic = self.fc1(x1)\n",
    "        x2 = x.view(-1, 196)\n",
    "        classifier = self.fc10(x2)\n",
    "        return critic,classifier\n",
    "\n",
    "model =  discriminator().to(device)\n",
    "#model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.949\n",
      "[1,   200] loss: 1.610\n",
      "[1,   300] loss: 1.505\n",
      "Epoch 1 Test accuracy: 52.830000 %\n",
      "[2,   100] loss: 1.328\n",
      "[2,   200] loss: 1.274\n",
      "[2,   300] loss: 1.219\n",
      "Epoch 2 Test accuracy: 59.440000 %\n",
      "[3,   100] loss: 1.068\n",
      "[3,   200] loss: 1.012\n",
      "[3,   300] loss: 1.014\n",
      "Epoch 3 Test accuracy: 64.090000 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-1fb6a216f55e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# print statistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m99\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# print every 100 mini-batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             print('[%d, %5d] loss: %.3f' %\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#  TRAINING\n",
    "epoch = 100\n",
    "learning_rate = 0.0001\n",
    "time1 = time.time()\n",
    "#running_loss = 0.0\n",
    "for epoch in range(epoch):  # loop over the dataset multiple times\n",
    "    if(epoch==50):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate/10.0\n",
    "    if(epoch==75):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate/100.0\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, (X_train_batch, Y_train_batch) in enumerate(trainloader):\n",
    "\n",
    "        if(Y_train_batch.shape[0] < batch_size):\n",
    "            continue\n",
    "\n",
    "        X_train_batch = Variable(X_train_batch).to(device)\n",
    "        Y_train_batch = Variable(Y_train_batch).to(device)\n",
    "        _, output = model(X_train_batch)\n",
    "\n",
    "        loss = criterion(output, Y_train_batch)\n",
    "        optimizer.zero_grad()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batch\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "        for group in optimizer.param_groups:\n",
    "            for p in group['params']:\n",
    "                state = optimizer.state[p]\n",
    "                if('step' in state and state['step']>=1024):\n",
    "                    state['step'] = 1000\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#if (epoch % 5 == 0):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            #images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            _,outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Epoch',epoch+1 ,'Test accuracy: %f %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(model,'cifar10.model')\n",
    "time2 = time.time()\n",
    "print(time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "98 % 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
