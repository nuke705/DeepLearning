{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T05:02:28.557352Z",
     "start_time": "2018-10-16T05:02:27.662747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 cuda:0\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import pickle\n",
    "\n",
    "import multiprocessing\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "# Setup\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(num_cpus, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T21:47:52.736448Z",
     "start_time": "2018-10-15T21:47:52.730958Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "dim_embedding = 1000\n",
    "k = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T05:02:37.662304Z",
     "start_time": "2018-10-16T05:02:37.594282Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def default_image_loader(path):\n",
    "    return Image.open(path).convert('RGB')\n",
    "\n",
    "class TripletImageLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_path, triplets_file_name, transform=None,\n",
    "                 loader=default_image_loader):\n",
    "        self.base_path = base_path  \n",
    "        self.filenamelist = []\n",
    "        triplets = []\n",
    "        for line in open(triplets_file_name):\n",
    "            triplets.append((line.split()[0], line.split()[1], line.split()[2])) # Q, P, N\n",
    "        self.triplets = triplets\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path1, path2, path3 = self.triplets[index]\n",
    "        img1 = self.loader(os.path.join(self.base_path,path1))\n",
    "        img2 = self.loader(os.path.join(self.base_path,path2))\n",
    "        img3 = self.loader(os.path.join(self.base_path,path3))\n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "            img3 = self.transform(img3)\n",
    "\n",
    "        return img1, img2, img3\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "    \n",
    "class EmbeddingImageLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_path, image_file_name, transform=None,\n",
    "                 loader=default_image_loader):\n",
    "        self.base_path = base_path  \n",
    "        self.filenamelist = []\n",
    "        files = []\n",
    "        for line in open(image_file_name):\n",
    "            files.append((line.rstrip('\\n')))\n",
    "        self.files = files\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.files[index]\n",
    "        img = self.loader(os.path.join(self.base_path,path))\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T05:03:28.086256Z",
     "start_time": "2018-10-16T05:03:28.077832Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transformations\n",
    "pretrain_image_size = 224\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [torchvision.transforms.Resize(pretrain_image_size),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "transform_test = transforms.Compose(\n",
    "    [torchvision.transforms.Resize(pretrain_image_size),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T21:48:03.294663Z",
     "start_time": "2018-10-15T21:47:52.847105Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#base_path = \"/projects/training/bauh/tiny-imagenet-200/\"\n",
    "base_path = \"\"\n",
    "train_sampler_file = \"E:/study/CS598/tiny-imagenet-200/train_sampler.txt\"\n",
    "trainset = TripletImageLoader(base_path, train_sampler_file, transform = transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=10, shuffle=False, num_workers=0)\n",
    "\n",
    "#test_sampler_file = \"test_sampler.txt\"\n",
    "#testset = TripletImageLoader(base_path, test_sampler_file, transform = transform_test)\n",
    "#testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=num_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_file = 'db.txt'\n",
    "val_file = 'val.txt'\n",
    "\n",
    "db_classes = np.array(pickle.load(open('db_classes.pkl','rb')))\n",
    "val_classes = np.array(pickle.load(open('val_classes.pkl','rb')))\n",
    "\n",
    "dataset = EmbeddingImageLoader(base_path, db_file, transform = transform_test)\n",
    "valset = EmbeddingImageLoader(base_path, val_file, transform = transform_test)\n",
    "\n",
    "testloader_db = DataLoader(dataset, batch_size=100, shuffle=False, num_workers=0)\n",
    "testloader_val = DataLoader(valset, batch_size=100, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T21:48:03.313740Z",
     "start_time": "2018-10-15T21:48:03.297937Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, embedding_net):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.embedding_net = embedding_net\n",
    "\n",
    "    def forward(self, Q, P, N):\n",
    "        Q_embedding = self.embedding_net(Q)\n",
    "        P_embedding = self.embedding_net(P)\n",
    "        N_embedding = self.embedding_net(N)\n",
    "        return Q_embedding, P_embedding, N_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T21:51:49.890612Z",
     "start_time": "2018-10-15T21:50:49.053739Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet = models.resnet101(pretrained=True)\n",
    "\n",
    "# change output layer\n",
    "#num_ftrs = net.fc.in_features\n",
    "#net.fc = nn.Linear(num_ftrs, dim_embedding)\n",
    "\n",
    "\n",
    "# for p in net.parameters():\n",
    "#     p.requires_grad=False\n",
    "# for p in net.fc.parameters():\n",
    "#     p.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T21:48:03.915471Z",
     "start_time": "2018-10-15T21:48:03.904335Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = TripletNet(resnet)\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.TripletMarginLoss(margin = 1)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T21:48:37.080069Z",
     "start_time": "2018-10-15T21:48:03.918626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average 10 epoch loss at epoch number 10 :\t 0.8108937978744507\n",
      "average 10 epoch loss at epoch number 20 :\t 0.8987368971109391\n",
      "average 10 epoch loss at epoch number 30 :\t 0.7618053764104843\n",
      "average 10 epoch loss at epoch number 40 :\t 0.7220729053020477\n",
      "average 10 epoch loss at epoch number 50 :\t 1.352463138103485\n",
      "average 10 epoch loss at epoch number 60 :\t 1.0354071706533432\n",
      "average 10 epoch loss at epoch number 70 :\t 0.8446289330720902\n",
      "average 10 epoch loss at epoch number 80 :\t 1.0003650814294816\n",
      "average 10 epoch loss at epoch number 90 :\t 0.8954549759626389\n",
      "average 10 epoch loss at epoch number 100 :\t 1.1094906479120255\n",
      "average 10 epoch loss at epoch number 110 :\t 1.0676131695508957\n",
      "average 10 epoch loss at epoch number 120 :\t 1.0442687630653382\n",
      "average 10 epoch loss at epoch number 130 :\t 0.6357000559568405\n",
      "average 10 epoch loss at epoch number 140 :\t 0.820886293053627\n",
      "average 10 epoch loss at epoch number 150 :\t 1.2252923548221588\n",
      "average 10 epoch loss at epoch number 160 :\t 0.7473713517189026\n",
      "average 10 epoch loss at epoch number 170 :\t 1.1184251636266709\n",
      "average 10 epoch loss at epoch number 180 :\t 1.0107453554868697\n",
      "average 10 epoch loss at epoch number 190 :\t 0.59499092400074\n",
      "average 10 epoch loss at epoch number 200 :\t 0.6337792783975601\n",
      "average 10 epoch loss at epoch number 210 :\t 0.6917198002338409\n",
      "average 10 epoch loss at epoch number 220 :\t 0.9765467762947082\n",
      "average 10 epoch loss at epoch number 230 :\t 0.8963945597410202\n",
      "average 10 epoch loss at epoch number 240 :\t 0.8150857090950012\n",
      "average 10 epoch loss at epoch number 250 :\t 0.8873861581087112\n",
      "average 10 epoch loss at epoch number 260 :\t 0.530334684252739\n",
      "average 10 epoch loss at epoch number 270 :\t 0.6534767240285874\n",
      "average 10 epoch loss at epoch number 280 :\t 0.9710471659898758\n",
      "average 10 epoch loss at epoch number 290 :\t 0.5404494851827621\n",
      "average 10 epoch loss at epoch number 300 :\t 0.657131913304329\n",
      "average 10 epoch loss at epoch number 310 :\t 0.7082562208175659\n",
      "average 10 epoch loss at epoch number 320 :\t 0.6369563430547714\n",
      "average 10 epoch loss at epoch number 330 :\t 0.5991904735565186\n",
      "average 10 epoch loss at epoch number 340 :\t 0.6865306913852691\n",
      "average 10 epoch loss at epoch number 350 :\t 0.6626703560352325\n",
      "average 10 epoch loss at epoch number 360 :\t 0.5405484139919281\n",
      "average 10 epoch loss at epoch number 370 :\t 0.5499972075223922\n",
      "average 10 epoch loss at epoch number 380 :\t 0.6123949646949768\n",
      "average 10 epoch loss at epoch number 390 :\t 0.596215796470642\n",
      "average 10 epoch loss at epoch number 400 :\t 0.7713341891765595\n",
      "average 10 epoch loss at epoch number 410 :\t 0.8543334811925888\n",
      "average 10 epoch loss at epoch number 420 :\t 0.9504304260015488\n",
      "average 10 epoch loss at epoch number 430 :\t 0.8368524879217147\n",
      "average 10 epoch loss at epoch number 440 :\t 0.6948875218629837\n",
      "average 10 epoch loss at epoch number 450 :\t 0.7869915038347244\n",
      "average 10 epoch loss at epoch number 460 :\t 0.6073491126298904\n",
      "average 10 epoch loss at epoch number 470 :\t 0.6675489246845245\n",
      "average 10 epoch loss at epoch number 480 :\t 0.9262294113636017\n",
      "average 10 epoch loss at epoch number 490 :\t 0.8733778208494186\n",
      "average 10 epoch loss at epoch number 500 :\t 0.5655392825603485\n",
      "average 10 epoch loss at epoch number 510 :\t 0.5902038037776947\n",
      "average 10 epoch loss at epoch number 520 :\t 0.5007190465927124\n",
      "average 10 epoch loss at epoch number 530 :\t 0.7048340797424316\n",
      "average 10 epoch loss at epoch number 540 :\t 0.6080613553524017\n",
      "average 10 epoch loss at epoch number 550 :\t 0.7376856118440628\n",
      "average 10 epoch loss at epoch number 560 :\t 0.6206937849521637\n",
      "average 10 epoch loss at epoch number 570 :\t 0.6869157791137696\n",
      "average 10 epoch loss at epoch number 580 :\t 0.561788460612297\n",
      "average 10 epoch loss at epoch number 590 :\t 0.6975098758935928\n",
      "average 10 epoch loss at epoch number 600 :\t 0.7024874299764633\n",
      "average 10 epoch loss at epoch number 610 :\t 0.5202753514051437\n",
      "average 10 epoch loss at epoch number 620 :\t 0.6257673144340515\n",
      "average 10 epoch loss at epoch number 630 :\t 0.5742755472660065\n",
      "average 10 epoch loss at epoch number 640 :\t 0.6660643190145492\n",
      "average 10 epoch loss at epoch number 650 :\t 0.6507938116788864\n",
      "average 10 epoch loss at epoch number 660 :\t 0.748441806435585\n",
      "average 10 epoch loss at epoch number 670 :\t 0.615098848938942\n",
      "average 10 epoch loss at epoch number 680 :\t 0.5342733293771744\n",
      "average 10 epoch loss at epoch number 690 :\t 0.6177838295698166\n",
      "average 10 epoch loss at epoch number 700 :\t 0.655783286690712\n",
      "average 10 epoch loss at epoch number 710 :\t 0.6625263005495071\n",
      "average 10 epoch loss at epoch number 720 :\t 0.697096437215805\n",
      "average 10 epoch loss at epoch number 730 :\t 0.5906260967254638\n",
      "average 10 epoch loss at epoch number 740 :\t 0.5831032216548919\n",
      "average 10 epoch loss at epoch number 750 :\t 0.7436760306358338\n",
      "average 10 epoch loss at epoch number 760 :\t 0.5513224631547928\n",
      "average 10 epoch loss at epoch number 770 :\t 0.570508673787117\n",
      "average 10 epoch loss at epoch number 780 :\t 0.5813259840011596\n",
      "average 10 epoch loss at epoch number 790 :\t 0.5838376820087433\n",
      "average 10 epoch loss at epoch number 800 :\t 0.49077375531196593\n",
      "average 10 epoch loss at epoch number 810 :\t 0.612331211566925\n",
      "average 10 epoch loss at epoch number 820 :\t 0.5684743851423264\n",
      "average 10 epoch loss at epoch number 830 :\t 0.6207010984420777\n",
      "average 10 epoch loss at epoch number 840 :\t 0.62323018014431\n",
      "average 10 epoch loss at epoch number 850 :\t 0.6288481622934341\n",
      "average 10 epoch loss at epoch number 860 :\t 0.4702261179685593\n",
      "average 10 epoch loss at epoch number 870 :\t 0.5512488782405853\n",
      "average 10 epoch loss at epoch number 880 :\t 0.5911202013492585\n",
      "average 10 epoch loss at epoch number 890 :\t 0.5787242025136947\n",
      "average 10 epoch loss at epoch number 900 :\t 0.6523938924074173\n",
      "average 10 epoch loss at epoch number 910 :\t 0.7119423538446427\n",
      "average 10 epoch loss at epoch number 920 :\t 0.49056471288204195\n",
      "average 10 epoch loss at epoch number 930 :\t 0.6342438668012619\n",
      "average 10 epoch loss at epoch number 940 :\t 0.5300286501646042\n",
      "average 10 epoch loss at epoch number 950 :\t 0.4829388201236725\n",
      "average 10 epoch loss at epoch number 960 :\t 0.6749040395021438\n",
      "average 10 epoch loss at epoch number 970 :\t 0.6209376126527786\n",
      "average 10 epoch loss at epoch number 980 :\t 0.540627658367157\n",
      "average 10 epoch loss at epoch number 990 :\t 0.703470128774643\n",
      "average 10 epoch loss at epoch number 1000 :\t 0.6768108278512954\n",
      "testing\n",
      "db embedding progress: 1000\n",
      "db embedding progress: 2000\n",
      "db embedding progress: 3000\n",
      "db embedding progress: 4000\n",
      "db embedding progress: 5000\n",
      "db embedding progress: 6000\n",
      "db embedding progress: 7000\n",
      "db embedding progress: 8000\n",
      "db embedding progress: 9000\n",
      "db embedding progress: 10000\n",
      "db embedding progress: 11000\n",
      "db embedding progress: 12000\n",
      "db embedding progress: 13000\n",
      "db embedding progress: 14000\n",
      "db embedding progress: 15000\n",
      "db embedding progress: 16000\n",
      "db embedding progress: 17000\n",
      "db embedding progress: 18000\n",
      "db embedding progress: 19000\n",
      "db embedding progress: 20000\n",
      "db embedding progress: 21000\n",
      "db embedding progress: 22000\n",
      "db embedding progress: 23000\n",
      "db embedding progress: 24000\n",
      "db embedding progress: 25000\n",
      "db embedding progress: 26000\n",
      "db embedding progress: 27000\n",
      "db embedding progress: 28000\n",
      "db embedding progress: 29000\n",
      "db embedding progress: 30000\n",
      "db embedding progress: 31000\n",
      "db embedding progress: 32000\n",
      "db embedding progress: 33000\n",
      "db embedding progress: 34000\n",
      "db embedding progress: 35000\n",
      "db embedding progress: 36000\n",
      "db embedding progress: 37000\n",
      "db embedding progress: 38000\n",
      "db embedding progress: 39000\n",
      "db embedding progress: 40000\n",
      "db embedding progress: 41000\n",
      "db embedding progress: 42000\n",
      "db embedding progress: 43000\n",
      "db embedding progress: 44000\n",
      "db embedding progress: 45000\n",
      "db embedding progress: 46000\n",
      "db embedding progress: 47000\n",
      "db embedding progress: 48000\n",
      "db embedding progress: 49000\n",
      "db embedding progress: 50000\n",
      "db embedding progress: 51000\n",
      "db embedding progress: 52000\n",
      "db embedding progress: 53000\n",
      "db embedding progress: 54000\n",
      "db embedding progress: 55000\n",
      "db embedding progress: 56000\n",
      "db embedding progress: 57000\n",
      "db embedding progress: 58000\n",
      "db embedding progress: 59000\n",
      "db embedding progress: 60000\n",
      "db embedding progress: 61000\n",
      "db embedding progress: 62000\n",
      "db embedding progress: 63000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db embedding progress: 64000\n",
      "db embedding progress: 65000\n",
      "db embedding progress: 66000\n",
      "db embedding progress: 67000\n",
      "db embedding progress: 68000\n",
      "db embedding progress: 69000\n",
      "db embedding progress: 70000\n",
      "db embedding progress: 71000\n",
      "db embedding progress: 72000\n",
      "db embedding progress: 73000\n",
      "db embedding progress: 74000\n",
      "db embedding progress: 75000\n",
      "db embedding progress: 76000\n",
      "db embedding progress: 77000\n",
      "db embedding progress: 78000\n",
      "db embedding progress: 79000\n",
      "db embedding progress: 80000\n",
      "db embedding progress: 81000\n",
      "db embedding progress: 82000\n",
      "db embedding progress: 83000\n",
      "db embedding progress: 84000\n",
      "db embedding progress: 85000\n",
      "db embedding progress: 86000\n",
      "db embedding progress: 87000\n",
      "db embedding progress: 88000\n",
      "db embedding progress: 89000\n",
      "db embedding progress: 90000\n",
      "db embedding progress: 91000\n",
      "db embedding progress: 92000\n",
      "db embedding progress: 93000\n",
      "db embedding progress: 94000\n",
      "db embedding progress: 95000\n",
      "db embedding progress: 96000\n",
      "db embedding progress: 97000\n",
      "db embedding progress: 98000\n",
      "db embedding progress: 99000\n",
      "db embedding progress: 100000\n",
      "val embedding progress: 1000\n",
      "val embedding progress: 2000\n",
      "val embedding progress: 3000\n",
      "val embedding progress: 4000\n",
      "val embedding progress: 5000\n",
      "val embedding progress: 6000\n",
      "val embedding progress: 7000\n",
      "val embedding progress: 8000\n",
      "val embedding progress: 9000\n",
      "val embedding progress: 10000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'db_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2932ba16ba79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0miv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_embedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb_embeddings\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mval_embeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m                 \u001b[0mtop_k_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlargest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'db_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "val_percision_over_time = []\n",
    "\n",
    "net.train()\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        net.train()\n",
    "        # get the inputs\n",
    "        Qin, Pin, Nin = data\n",
    "        Qin, Pin, Nin = Qin.to(device), Pin.to(device), Nin.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        eQ, eP, eN = net(Qin, Pin, Nin)\n",
    "        \n",
    "        loss_tripletNet = criterion(eQ, eP, eN)\n",
    "        loss_embeddingNet = eQ.norm(2) + eP.norm(2) + eN.norm(2)\n",
    "        loss = loss_tripletNet + 0.001 * loss_embeddingNet\n",
    "        \n",
    "        #  backward + optimize\n",
    "        loss.backward()\n",
    "\n",
    "        for group in optimizer.param_groups:\n",
    "            for p in group['params']:\n",
    "                state = optimizer.state[p]\n",
    "                if('step' in state and state['step']>=1024):\n",
    "                    state['step'] = 1000\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 10 == 0:\n",
    "            print('average 10 epoch loss at epoch number',(i+1),':\\t',running_loss/10)\n",
    "            running_loss = 0.0\n",
    "    \n",
    "        # validate\n",
    "        if (i+1) % (200*500//10//10) == 0: # 1/10 of an epoch\n",
    "            print(\"testing\")\n",
    "            net.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            embeddings_db = []\n",
    "            embeddings_val = []\n",
    "            with torch.no_grad():\n",
    "                progress_counter = 0\n",
    "                for data in testloader_db:\n",
    "                    Qin = data\n",
    "                    Qin = Qin.to(device)\n",
    "\n",
    "                    eQ = resnet(Qin)\n",
    "                    embeddings_db.append(eQ)\n",
    "\n",
    "                    progress_counter += 100\n",
    "                    if progress_counter % 1000 == 0:\n",
    "                        print('db embedding progress:',progress_counter)\n",
    "\n",
    "                progress_counter = 0\n",
    "                for data in testloader_val:\n",
    "                    Qin = data\n",
    "                    Qin = Qin.to(device)\n",
    "\n",
    "                    eQ = resnet(Qin)\n",
    "                    embeddings_val.append(eQ)\n",
    "\n",
    "                    progress_counter += 100\n",
    "                    if progress_counter % 1000 == 0:\n",
    "                        print('val embedding progress:',progress_counter)\n",
    "                    \n",
    "            db_embedding = torch.cat(embeddings_db)\n",
    "            val_embedding = torch.cat(embeddings_val)\n",
    "            \n",
    "            val_top_k_percision = []\n",
    "            \n",
    "            for iv in range(val_embedding.size(0)):\n",
    "                distances = torch.norm((db_embedding-val_embedding[iv]),p=2,dim=1)\n",
    "                top_k_idx = torch.topk(distances,k=k,dim=0,largest=False,sorted=False)[1]\n",
    "\n",
    "                top_k_classes = db_classes[top_k_idx]\n",
    "                val_class = val_classes[iv]\n",
    "                top_k_percision = (top_k_classes == val_class).sum()/k\n",
    "            \n",
    "                val_top_k_percision.append(top_k_percision)\n",
    "            \n",
    "            print(\"testing done\")\n",
    "            val_percision_over_time.append(val_top_k_percision)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing done\n"
     ]
    }
   ],
   "source": [
    "         \n",
    "db_embedding = torch.cat(embeddings_db)\n",
    "val_embedding = torch.cat(embeddings_val)\n",
    "            \n",
    "val_top_k_percision = []\n",
    "            \n",
    "for iv in range(val_embedding.size(0)):\n",
    "    distances = torch.norm((db_embedding-val_embedding[iv]),p=2,dim=1)\n",
    "    top_k_idx = torch.topk(distances,k=k,dim=0,largest=False,sorted=False)[1]\n",
    "\n",
    "    top_k_classes = db_classes[top_k_idx]\n",
    "    val_class = val_classes[iv]\n",
    "    top_k_percision = (top_k_classes == val_class).sum()/k\n",
    "            \n",
    "    val_top_k_percision.append(top_k_percision)\n",
    "            \n",
    "print(\"testing done\")\n",
    "val_percision_over_time.append(val_top_k_percision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.8,\n",
       "  0.0,\n",
       "  0.06666666666666667,\n",
       "  0.4,\n",
       "  0.03333333333333333,\n",
       "  0.8333333333333334,\n",
       "  0.36666666666666664,\n",
       "  0.6,\n",
       "  1.0,\n",
       "  0.3333333333333333,\n",
       "  0.1,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  0.1,\n",
       "  0.0,\n",
       "  0.2,\n",
       "  0.06666666666666667,\n",
       "  0.7666666666666667,\n",
       "  0.6,\n",
       "  0.06666666666666667,\n",
       "  0.23333333333333334,\n",
       "  0.9666666666666667,\n",
       "  0.0,\n",
       "  0.06666666666666667,\n",
       "  0.7,\n",
       "  0.8333333333333334,\n",
       "  0.6333333333333333,\n",
       "  0.1,\n",
       "  0.2,\n",
       "  0.36666666666666664,\n",
       "  0.06666666666666667,\n",
       "  0.1,\n",
       "  0.13333333333333333,\n",
       "  0.5333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.5666666666666667,\n",
       "  0.4,\n",
       "  0.03333333333333333,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  0.1,\n",
       "  0.4666666666666667,\n",
       "  1.0,\n",
       "  0.06666666666666667,\n",
       "  0.5,\n",
       "  0.06666666666666667,\n",
       "  0.06666666666666667,\n",
       "  0.9666666666666667,\n",
       "  0.5666666666666667,\n",
       "  0.1,\n",
       "  0.06666666666666667,\n",
       "  0.3,\n",
       "  0.6666666666666666,\n",
       "  0.23333333333333334,\n",
       "  0.3333333333333333,\n",
       "  0.23333333333333334,\n",
       "  0.5333333333333333,\n",
       "  0.0,\n",
       "  0.3,\n",
       "  0.0,\n",
       "  0.26666666666666666,\n",
       "  0.5333333333333333,\n",
       "  0.9333333333333333,\n",
       "  0.7333333333333333,\n",
       "  0.5333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.9333333333333333,\n",
       "  0.8,\n",
       "  0.8,\n",
       "  0.06666666666666667,\n",
       "  0.1,\n",
       "  0.03333333333333333,\n",
       "  0.13333333333333333,\n",
       "  0.9666666666666667,\n",
       "  1.0,\n",
       "  0.03333333333333333,\n",
       "  0.6333333333333333,\n",
       "  0.6333333333333333,\n",
       "  0.5,\n",
       "  0.7333333333333333,\n",
       "  1.0,\n",
       "  0.9666666666666667,\n",
       "  0.9,\n",
       "  0.9,\n",
       "  0.5333333333333333,\n",
       "  0.06666666666666667,\n",
       "  0.36666666666666664,\n",
       "  1.0,\n",
       "  0.6666666666666666,\n",
       "  0.9666666666666667,\n",
       "  0.06666666666666667,\n",
       "  1.0,\n",
       "  0.36666666666666664,\n",
       "  0.03333333333333333,\n",
       "  0.4666666666666667,\n",
       "  0.4,\n",
       "  0.13333333333333333,\n",
       "  0.0,\n",
       "  0.8666666666666667,\n",
       "  0.7,\n",
       "  0.0,\n",
       "  0.36666666666666664,\n",
       "  0.2,\n",
       "  0.1,\n",
       "  0.8666666666666667,\n",
       "  1.0,\n",
       "  0.43333333333333335,\n",
       "  0.03333333333333333,\n",
       "  0.7,\n",
       "  0.06666666666666667,\n",
       "  0.06666666666666667,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.1,\n",
       "  0.5,\n",
       "  0.03333333333333333,\n",
       "  0.43333333333333335,\n",
       "  0.0,\n",
       "  0.06666666666666667,\n",
       "  0.26666666666666666,\n",
       "  0.06666666666666667,\n",
       "  0.26666666666666666,\n",
       "  0.6333333333333333,\n",
       "  0.6666666666666666,\n",
       "  0.5333333333333333,\n",
       "  0.9333333333333333,\n",
       "  0.6333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.0,\n",
       "  0.8333333333333334,\n",
       "  0.7666666666666667,\n",
       "  0.3,\n",
       "  0.9,\n",
       "  0.16666666666666666,\n",
       "  0.5666666666666667,\n",
       "  0.0,\n",
       "  0.06666666666666667,\n",
       "  0.0,\n",
       "  0.06666666666666667,\n",
       "  1.0,\n",
       "  0.3333333333333333,\n",
       "  0.1,\n",
       "  0.8666666666666667,\n",
       "  0.9666666666666667,\n",
       "  0.13333333333333333,\n",
       "  0.0,\n",
       "  0.9333333333333333,\n",
       "  0.0,\n",
       "  0.4,\n",
       "  0.8666666666666667,\n",
       "  0.8,\n",
       "  0.0,\n",
       "  0.8333333333333334,\n",
       "  0.6666666666666666,\n",
       "  0.8666666666666667,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.9666666666666667,\n",
       "  0.0,\n",
       "  0.8666666666666667,\n",
       "  0.9333333333333333,\n",
       "  0.0,\n",
       "  0.03333333333333333,\n",
       "  0.9,\n",
       "  0.9666666666666667,\n",
       "  0.9333333333333333,\n",
       "  0.6333333333333333,\n",
       "  0.06666666666666667,\n",
       "  0.03333333333333333,\n",
       "  0.7666666666666667,\n",
       "  1.0,\n",
       "  0.7666666666666667,\n",
       "  0.16666666666666666,\n",
       "  0.03333333333333333,\n",
       "  0.8666666666666667,\n",
       "  0.06666666666666667,\n",
       "  0.9333333333333333,\n",
       "  0.0,\n",
       "  0.4,\n",
       "  0.8333333333333334,\n",
       "  0.2,\n",
       "  0.06666666666666667,\n",
       "  0.4666666666666667,\n",
       "  0.7333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.8,\n",
       "  0.5,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.06666666666666667,\n",
       "  1.0,\n",
       "  0.7666666666666667,\n",
       "  0.7,\n",
       "  0.26666666666666666,\n",
       "  0.3,\n",
       "  0.3,\n",
       "  0.8,\n",
       "  0.9666666666666667,\n",
       "  0.13333333333333333,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.1,\n",
       "  0.4,\n",
       "  0.6333333333333333,\n",
       "  0.06666666666666667,\n",
       "  0.6,\n",
       "  1.0,\n",
       "  0.7333333333333333,\n",
       "  0.0,\n",
       "  0.03333333333333333,\n",
       "  1.0,\n",
       "  0.3333333333333333,\n",
       "  1.0,\n",
       "  0.03333333333333333,\n",
       "  0.6,\n",
       "  0.9333333333333333,\n",
       "  0.23333333333333334,\n",
       "  0.06666666666666667,\n",
       "  0.06666666666666667,\n",
       "  1.0,\n",
       "  0.3333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.23333333333333334,\n",
       "  0.26666666666666666,\n",
       "  0.26666666666666666,\n",
       "  0.43333333333333335,\n",
       "  0.1,\n",
       "  0.6333333333333333,\n",
       "  0.03333333333333333,\n",
       "  1.0,\n",
       "  0.06666666666666667,\n",
       "  0.3333333333333333,\n",
       "  0.7666666666666667,\n",
       "  0.43333333333333335,\n",
       "  0.0,\n",
       "  0.7,\n",
       "  0.8,\n",
       "  0.03333333333333333,\n",
       "  0.1,\n",
       "  0.0,\n",
       "  0.4666666666666667,\n",
       "  0.0,\n",
       "  0.9333333333333333,\n",
       "  0.36666666666666664,\n",
       "  0.1,\n",
       "  0.13333333333333333,\n",
       "  0.7,\n",
       "  0.0,\n",
       "  0.8666666666666667,\n",
       "  0.26666666666666666,\n",
       "  0.4,\n",
       "  0.13333333333333333,\n",
       "  0.06666666666666667,\n",
       "  0.3,\n",
       "  0.4,\n",
       "  0.16666666666666666,\n",
       "  0.8666666666666667,\n",
       "  0.0,\n",
       "  0.23333333333333334,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.1,\n",
       "  0.9333333333333333,\n",
       "  0.6,\n",
       "  0.1,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.4666666666666667,\n",
       "  0.5,\n",
       "  0.9333333333333333,\n",
       "  0.9333333333333333,\n",
       "  0.6333333333333333,\n",
       "  0.26666666666666666,\n",
       "  1.0,\n",
       "  0.43333333333333335,\n",
       "  0.5333333333333333,\n",
       "  0.43333333333333335,\n",
       "  1.0,\n",
       "  0.4666666666666667,\n",
       "  0.03333333333333333,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.06666666666666667,\n",
       "  0.3,\n",
       "  0.2,\n",
       "  0.7666666666666667,\n",
       "  0.9,\n",
       "  0.13333333333333333,\n",
       "  0.5333333333333333,\n",
       "  0.0,\n",
       "  0.06666666666666667,\n",
       "  1.0,\n",
       "  0.36666666666666664,\n",
       "  0.4,\n",
       "  0.6666666666666666,\n",
       "  0.2,\n",
       "  0.4,\n",
       "  0.16666666666666666,\n",
       "  0.2,\n",
       "  0.13333333333333333,\n",
       "  0.9,\n",
       "  0.4666666666666667,\n",
       "  0.36666666666666664,\n",
       "  0.0,\n",
       "  0.26666666666666666,\n",
       "  0.3,\n",
       "  0.26666666666666666,\n",
       "  0.03333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.26666666666666666,\n",
       "  0.03333333333333333,\n",
       "  0.16666666666666666,\n",
       "  1.0,\n",
       "  0.06666666666666667,\n",
       "  0.5666666666666667,\n",
       "  0.2,\n",
       "  0.13333333333333333,\n",
       "  0.26666666666666666,\n",
       "  0.6666666666666666,\n",
       "  0.3333333333333333,\n",
       "  0.4,\n",
       "  0.8,\n",
       "  0.7666666666666667,\n",
       "  0.3,\n",
       "  0.23333333333333334,\n",
       "  1.0,\n",
       "  0.9333333333333333,\n",
       "  0.0,\n",
       "  0.1,\n",
       "  0.2,\n",
       "  0.3,\n",
       "  0.5333333333333333,\n",
       "  0.06666666666666667,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.6,\n",
       "  0.9666666666666667,\n",
       "  0.0,\n",
       "  0.16666666666666666,\n",
       "  1.0,\n",
       "  0.7333333333333333,\n",
       "  0.9333333333333333,\n",
       "  0.0,\n",
       "  0.13333333333333333,\n",
       "  0.7666666666666667,\n",
       "  0.03333333333333333,\n",
       "  0.0,\n",
       "  0.7333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.2,\n",
       "  0.8333333333333334,\n",
       "  0.7,\n",
       "  0.43333333333333335,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.36666666666666664,\n",
       "  1.0,\n",
       "  0.6666666666666666,\n",
       "  0.23333333333333334,\n",
       "  0.9333333333333333,\n",
       "  0.7333333333333333,\n",
       "  0.8333333333333334,\n",
       "  0.2,\n",
       "  0.6,\n",
       "  0.6333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.0,\n",
       "  0.3,\n",
       "  0.7,\n",
       "  0.3,\n",
       "  0.5666666666666667,\n",
       "  0.03333333333333333,\n",
       "  0.0,\n",
       "  0.3,\n",
       "  0.0,\n",
       "  0.03333333333333333,\n",
       "  0.5333333333333333,\n",
       "  0.6666666666666666,\n",
       "  0.16666666666666666,\n",
       "  0.26666666666666666,\n",
       "  0.26666666666666666,\n",
       "  0.03333333333333333,\n",
       "  0.4666666666666667,\n",
       "  0.7333333333333333,\n",
       "  0.1,\n",
       "  0.8333333333333334,\n",
       "  0.6333333333333333,\n",
       "  0.23333333333333334,\n",
       "  0.0,\n",
       "  0.26666666666666666,\n",
       "  0.13333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.2,\n",
       "  0.3333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.23333333333333334,\n",
       "  0.8333333333333334,\n",
       "  0.1,\n",
       "  0.7666666666666667,\n",
       "  0.9,\n",
       "  0.0,\n",
       "  0.26666666666666666,\n",
       "  0.03333333333333333,\n",
       "  0.4666666666666667,\n",
       "  0.26666666666666666,\n",
       "  0.03333333333333333,\n",
       "  0.3333333333333333,\n",
       "  0.16666666666666666,\n",
       "  0.8,\n",
       "  0.2,\n",
       "  0.03333333333333333,\n",
       "  0.3333333333333333,\n",
       "  0.6666666666666666,\n",
       "  0.0,\n",
       "  0.06666666666666667,\n",
       "  0.1,\n",
       "  0.43333333333333335,\n",
       "  0.0,\n",
       "  0.1,\n",
       "  0.2,\n",
       "  0.03333333333333333,\n",
       "  0.2,\n",
       "  0.13333333333333333,\n",
       "  0.36666666666666664,\n",
       "  0.6,\n",
       "  0.06666666666666667,\n",
       "  0.0,\n",
       "  0.03333333333333333,\n",
       "  0.26666666666666666,\n",
       "  0.7666666666666667,\n",
       "  0.23333333333333334,\n",
       "  0.03333333333333333,\n",
       "  0.7333333333333333,\n",
       "  0.8666666666666667,\n",
       "  0.6333333333333333,\n",
       "  0.16666666666666666,\n",
       "  0.43333333333333335,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  0.16666666666666666,\n",
       "  0.7666666666666667,\n",
       "  0.0,\n",
       "  0.4666666666666667,\n",
       "  0.26666666666666666,\n",
       "  0.0,\n",
       "  0.1,\n",
       "  0.13333333333333333,\n",
       "  0.36666666666666664,\n",
       "  0.13333333333333333,\n",
       "  0.43333333333333335,\n",
       "  0.5333333333333333,\n",
       "  0.7666666666666667,\n",
       "  0.4,\n",
       "  0.5333333333333333,\n",
       "  0.9666666666666667,\n",
       "  0.13333333333333333,\n",
       "  0.5666666666666667,\n",
       "  0.13333333333333333,\n",
       "  0.23333333333333334,\n",
       "  0.13333333333333333,\n",
       "  0.8333333333333334,\n",
       "  0.7,\n",
       "  0.0,\n",
       "  0.36666666666666664,\n",
       "  0.9,\n",
       "  0.06666666666666667,\n",
       "  0.6,\n",
       "  0.1,\n",
       "  0.7666666666666667,\n",
       "  0.7333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.2,\n",
       "  0.06666666666666667,\n",
       "  0.16666666666666666,\n",
       "  0.13333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.6333333333333333,\n",
       "  0.7,\n",
       "  0.0,\n",
       "  0.4666666666666667,\n",
       "  0.06666666666666667,\n",
       "  0.7,\n",
       "  0.03333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.6333333333333333,\n",
       "  0.06666666666666667,\n",
       "  0.5,\n",
       "  0.9,\n",
       "  0.3,\n",
       "  1.0,\n",
       "  0.03333333333333333,\n",
       "  0.6666666666666666,\n",
       "  0.06666666666666667,\n",
       "  0.2,\n",
       "  0.0,\n",
       "  0.03333333333333333,\n",
       "  1.0,\n",
       "  0.1,\n",
       "  0.7,\n",
       "  0.0,\n",
       "  0.5333333333333333,\n",
       "  0.06666666666666667,\n",
       "  0.43333333333333335,\n",
       "  0.4,\n",
       "  0.0,\n",
       "  0.4,\n",
       "  0.03333333333333333,\n",
       "  0.0,\n",
       "  0.4666666666666667,\n",
       "  0.6333333333333333,\n",
       "  0.06666666666666667,\n",
       "  0.4666666666666667,\n",
       "  0.06666666666666667,\n",
       "  0.7,\n",
       "  0.6666666666666666,\n",
       "  0.26666666666666666,\n",
       "  0.0,\n",
       "  0.3,\n",
       "  0.0,\n",
       "  0.16666666666666666,\n",
       "  0.3,\n",
       "  0.36666666666666664,\n",
       "  1.0,\n",
       "  0.36666666666666664,\n",
       "  0.3333333333333333,\n",
       "  0.4666666666666667,\n",
       "  0.1,\n",
       "  0.4666666666666667,\n",
       "  0.5,\n",
       "  0.1,\n",
       "  0.3,\n",
       "  0.36666666666666664,\n",
       "  0.9666666666666667,\n",
       "  0.6666666666666666,\n",
       "  0.9666666666666667,\n",
       "  0.23333333333333334,\n",
       "  0.1,\n",
       "  0.6,\n",
       "  0.06666666666666667,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  0.7,\n",
       "  0.6666666666666666,\n",
       "  0.06666666666666667,\n",
       "  0.9333333333333333,\n",
       "  0.4,\n",
       "  0.13333333333333333,\n",
       "  0.06666666666666667,\n",
       "  0.26666666666666666,\n",
       "  0.3,\n",
       "  0.4,\n",
       "  0.7666666666666667,\n",
       "  0.9666666666666667,\n",
       "  0.2,\n",
       "  1.0,\n",
       "  0.2,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  0.03333333333333333,\n",
       "  0.7,\n",
       "  0.13333333333333333,\n",
       "  0.06666666666666667,\n",
       "  0.0,\n",
       "  0.26666666666666666,\n",
       "  0.0,\n",
       "  0.5333333333333333,\n",
       "  1.0,\n",
       "  0.8666666666666667,\n",
       "  0.7666666666666667,\n",
       "  0.26666666666666666,\n",
       "  0.3333333333333333,\n",
       "  0.36666666666666664,\n",
       "  0.1,\n",
       "  0.7666666666666667,\n",
       "  0.4666666666666667,\n",
       "  0.06666666666666667,\n",
       "  0.6333333333333333,\n",
       "  0.0,\n",
       "  0.5,\n",
       "  0.23333333333333334,\n",
       "  0.43333333333333335,\n",
       "  0.26666666666666666,\n",
       "  0.9666666666666667,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.1,\n",
       "  0.7333333333333333,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.06666666666666667,\n",
       "  1.0,\n",
       "  0.23333333333333334,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.03333333333333333,\n",
       "  0.0,\n",
       "  0.13333333333333333,\n",
       "  0.23333333333333334,\n",
       "  0.0,\n",
       "  0.9666666666666667,\n",
       "  0.4,\n",
       "  1.0,\n",
       "  0.06666666666666667,\n",
       "  0.2,\n",
       "  0.7666666666666667,\n",
       "  0.9,\n",
       "  0.03333333333333333,\n",
       "  0.1,\n",
       "  0.5,\n",
       "  0.6666666666666666,\n",
       "  0.43333333333333335,\n",
       "  0.0,\n",
       "  0.06666666666666667,\n",
       "  0.0,\n",
       "  0.43333333333333335,\n",
       "  0.1,\n",
       "  0.43333333333333335,\n",
       "  0.13333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.5333333333333333,\n",
       "  0.3,\n",
       "  0.8333333333333334,\n",
       "  0.16666666666666666,\n",
       "  0.9333333333333333,\n",
       "  0.1,\n",
       "  0.5333333333333333,\n",
       "  0.8333333333333334,\n",
       "  0.0,\n",
       "  0.4,\n",
       "  0.2,\n",
       "  1.0,\n",
       "  0.4,\n",
       "  0.1,\n",
       "  0.0,\n",
       "  0.06666666666666667,\n",
       "  0.2,\n",
       "  0.3333333333333333,\n",
       "  0.5333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.9333333333333333,\n",
       "  0.43333333333333335,\n",
       "  0.9666666666666667,\n",
       "  0.4666666666666667,\n",
       "  0.6,\n",
       "  0.9333333333333333,\n",
       "  0.4,\n",
       "  0.06666666666666667,\n",
       "  0.06666666666666667,\n",
       "  0.5333333333333333,\n",
       "  0.6,\n",
       "  0.36666666666666664,\n",
       "  0.06666666666666667,\n",
       "  0.23333333333333334,\n",
       "  0.03333333333333333,\n",
       "  0.2,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.06666666666666667,\n",
       "  0.9333333333333333,\n",
       "  0.13333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.36666666666666664,\n",
       "  0.5333333333333333,\n",
       "  0.0,\n",
       "  0.2,\n",
       "  0.8333333333333334,\n",
       "  0.6666666666666666,\n",
       "  0.4666666666666667,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2,\n",
       "  0.1,\n",
       "  0.16666666666666666,\n",
       "  0.6333333333333333,\n",
       "  0.26666666666666666,\n",
       "  0.13333333333333333,\n",
       "  0.06666666666666667,\n",
       "  0.0,\n",
       "  0.6,\n",
       "  0.13333333333333333,\n",
       "  0.4,\n",
       "  0.6666666666666666,\n",
       "  1.0,\n",
       "  0.7333333333333333,\n",
       "  0.0,\n",
       "  0.7333333333333333,\n",
       "  0.5333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.2,\n",
       "  0.26666666666666666,\n",
       "  0.03333333333333333,\n",
       "  0.5333333333333333,\n",
       "  0.7,\n",
       "  0.23333333333333334,\n",
       "  0.6666666666666666,\n",
       "  0.5,\n",
       "  0.1,\n",
       "  0.5,\n",
       "  0.06666666666666667,\n",
       "  0.5666666666666667,\n",
       "  0.0,\n",
       "  0.13333333333333333,\n",
       "  0.2,\n",
       "  0.2,\n",
       "  0.43333333333333335,\n",
       "  0.3,\n",
       "  0.2,\n",
       "  1.0,\n",
       "  0.2,\n",
       "  0.0,\n",
       "  0.8666666666666667,\n",
       "  0.4,\n",
       "  0.06666666666666667,\n",
       "  0.1,\n",
       "  0.23333333333333334,\n",
       "  0.13333333333333333,\n",
       "  0.13333333333333333,\n",
       "  1.0,\n",
       "  0.4666666666666667,\n",
       "  0.3333333333333333,\n",
       "  0.13333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.36666666666666664,\n",
       "  1.0,\n",
       "  0.23333333333333334,\n",
       "  0.9666666666666667,\n",
       "  0.7333333333333333,\n",
       "  0.43333333333333335,\n",
       "  1.0,\n",
       "  0.06666666666666667,\n",
       "  0.0,\n",
       "  0.03333333333333333,\n",
       "  0.06666666666666667,\n",
       "  0.16666666666666666,\n",
       "  0.1,\n",
       "  0.03333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.26666666666666666,\n",
       "  0.1,\n",
       "  0.9333333333333333,\n",
       "  0.13333333333333333,\n",
       "  0.9666666666666667,\n",
       "  0.03333333333333333,\n",
       "  0.1,\n",
       "  0.4,\n",
       "  0.8333333333333334,\n",
       "  0.4666666666666667,\n",
       "  0.16666666666666666,\n",
       "  0.16666666666666666,\n",
       "  0.0,\n",
       "  0.9666666666666667,\n",
       "  0.5666666666666667,\n",
       "  0.2,\n",
       "  0.9,\n",
       "  0.7666666666666667,\n",
       "  0.1,\n",
       "  0.36666666666666664,\n",
       "  0.5333333333333333,\n",
       "  0.0,\n",
       "  0.6,\n",
       "  0.4,\n",
       "  0.06666666666666667,\n",
       "  0.03333333333333333,\n",
       "  0.2,\n",
       "  0.9,\n",
       "  0.8,\n",
       "  0.9333333333333333,\n",
       "  0.7333333333333333,\n",
       "  0.06666666666666667,\n",
       "  0.03333333333333333,\n",
       "  0.6666666666666666,\n",
       "  0.5,\n",
       "  0.4,\n",
       "  0.16666666666666666,\n",
       "  0.5333333333333333,\n",
       "  0.1,\n",
       "  1.0,\n",
       "  0.13333333333333333,\n",
       "  0.06666666666666667,\n",
       "  0.0,\n",
       "  0.7,\n",
       "  0.4666666666666667,\n",
       "  0.1,\n",
       "  0.13333333333333333,\n",
       "  0.3,\n",
       "  0.9666666666666667,\n",
       "  0.1,\n",
       "  0.16666666666666666,\n",
       "  0.6,\n",
       "  1.0,\n",
       "  0.26666666666666666,\n",
       "  0.9333333333333333,\n",
       "  0.16666666666666666,\n",
       "  0.3333333333333333,\n",
       "  0.13333333333333333,\n",
       "  0.6666666666666666,\n",
       "  0.06666666666666667,\n",
       "  0.13333333333333333,\n",
       "  0.03333333333333333,\n",
       "  0.1,\n",
       "  0.8666666666666667,\n",
       "  0.4666666666666667,\n",
       "  0.0,\n",
       "  0.5333333333333333,\n",
       "  0.4,\n",
       "  0.1,\n",
       "  0.1,\n",
       "  0.3,\n",
       "  0.0,\n",
       "  0.5333333333333333,\n",
       "  0.7666666666666667,\n",
       "  0.03333333333333333,\n",
       "  0.06666666666666667,\n",
       "  0.1,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  0.06666666666666667,\n",
       "  0.03333333333333333,\n",
       "  0.9666666666666667,\n",
       "  0.9666666666666667,\n",
       "  0.3,\n",
       "  0.13333333333333333,\n",
       "  0.6,\n",
       "  0.5333333333333333,\n",
       "  0.13333333333333333,\n",
       "  0.16666666666666666,\n",
       "  0.1,\n",
       "  0.26666666666666666,\n",
       "  0.9666666666666667,\n",
       "  0.26666666666666666,\n",
       "  0.13333333333333333,\n",
       "  0.43333333333333335,\n",
       "  0.4,\n",
       "  0.03333333333333333,\n",
       "  0.7333333333333333,\n",
       "  1.0,\n",
       "  0.8333333333333334,\n",
       "  0.8666666666666667,\n",
       "  0.13333333333333333,\n",
       "  0.3,\n",
       "  0.6666666666666666,\n",
       "  0.4,\n",
       "  0.6,\n",
       "  0.03333333333333333,\n",
       "  0.9,\n",
       "  0.5666666666666667,\n",
       "  0.0,\n",
       "  0.7666666666666667,\n",
       "  0.03333333333333333,\n",
       "  0.16666666666666666,\n",
       "  0.2,\n",
       "  0.06666666666666667,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.4,\n",
       "  0.16666666666666666,\n",
       "  0.36666666666666664,\n",
       "  0.2,\n",
       "  0.3,\n",
       "  0.3333333333333333,\n",
       "  0.2,\n",
       "  1.0,\n",
       "  0.7,\n",
       "  0.13333333333333333,\n",
       "  1.0,\n",
       "  0.5333333333333333,\n",
       "  0.0,\n",
       "  0.03333333333333333,\n",
       "  0.2,\n",
       "  0.7333333333333333,\n",
       "  0.0,\n",
       "  0.36666666666666664,\n",
       "  0.8,\n",
       "  0.0,\n",
       "  0.9666666666666667,\n",
       "  0.2,\n",
       "  1.0,\n",
       "  0.9666666666666667,\n",
       "  0.43333333333333335,\n",
       "  0.23333333333333334,\n",
       "  0.23333333333333334,\n",
       "  0.03333333333333333,\n",
       "  0.1,\n",
       "  0.03333333333333333,\n",
       "  0.13333333333333333,\n",
       "  0.06666666666666667,\n",
       "  0.23333333333333334,\n",
       "  0.7333333333333333,\n",
       "  0.8333333333333334,\n",
       "  0.36666666666666664,\n",
       "  1.0,\n",
       "  0.43333333333333335,\n",
       "  0.03333333333333333,\n",
       "  0.8,\n",
       "  0.16666666666666666,\n",
       "  0.03333333333333333,\n",
       "  0.36666666666666664,\n",
       "  0.4666666666666667,\n",
       "  0.5666666666666667,\n",
       "  0.5333333333333333,\n",
       "  0.0,\n",
       "  0.3,\n",
       "  0.6,\n",
       "  0.06666666666666667,\n",
       "  0.03333333333333333,\n",
       "  0.9666666666666667,\n",
       "  0.06666666666666667,\n",
       "  0.0,\n",
       "  0.1,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.1,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.16666666666666666,\n",
       "  0.13333333333333333,\n",
       "  0.0,\n",
       "  0.23333333333333334,\n",
       "  0.06666666666666667,\n",
       "  0.0,\n",
       "  0.8,\n",
       "  0.36666666666666664,\n",
       "  0.6666666666666666,\n",
       "  1.0,\n",
       "  0.6,\n",
       "  0.3,\n",
       "  0.26666666666666666,\n",
       "  0.7666666666666667,\n",
       "  0.8333333333333334,\n",
       "  0.1,\n",
       "  0.8,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  0.1,\n",
       "  0.06666666666666667,\n",
       "  0.8333333333333334,\n",
       "  0.0,\n",
       "  0.9666666666666667,\n",
       "  0.6666666666666666,\n",
       "  0.23333333333333334,\n",
       "  0.03333333333333333,\n",
       "  0.36666666666666664,\n",
       "  0.03333333333333333,\n",
       "  0.1,\n",
       "  0.7666666666666667,\n",
       "  0.4666666666666667,\n",
       "  1.0,\n",
       "  0.3333333333333333,\n",
       "  0.5333333333333333,\n",
       "  0.16666666666666666,\n",
       "  0.6333333333333333,\n",
       "  0.7333333333333333,\n",
       "  0.06666666666666667,\n",
       "  0.2,\n",
       "  0.2,\n",
       "  0.1,\n",
       "  0.23333333333333334,\n",
       "  0.1,\n",
       "  0.3333333333333333,\n",
       "  0.43333333333333335,\n",
       "  0.1,\n",
       "  0.03333333333333333,\n",
       "  0.8333333333333334,\n",
       "  0.3,\n",
       "  0.6333333333333333,\n",
       "  0.2,\n",
       "  0.6,\n",
       "  0.7,\n",
       "  0.8,\n",
       "  0.6333333333333333,\n",
       "  0.5,\n",
       "  0.13333333333333333,\n",
       "  0.4666666666666667,\n",
       "  0.5333333333333333,\n",
       "  0.7666666666666667,\n",
       "  0.13333333333333333,\n",
       "  0.13333333333333333,\n",
       "  0.5333333333333333,\n",
       "  0.13333333333333333,\n",
       "  0.23333333333333334,\n",
       "  0.03333333333333333,\n",
       "  0.5666666666666667,\n",
       "  0.03333333333333333,\n",
       "  0.23333333333333334,\n",
       "  0.03333333333333333,\n",
       "  0.0,\n",
       "  0.5666666666666667,\n",
       "  0.7,\n",
       "  ...]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_percision_over_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
