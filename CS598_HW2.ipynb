{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CS 598 HW2\n",
    "# Student: Zhi Ji, code is a modified version of professor Sirigano's work\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import time\n",
    "import copy\n",
    "from random import randint\n",
    "\n",
    "#load MNIST dat\n",
    "MNIST_data = h5py.File('MNISTdata.hdf5', 'r')\n",
    "x_train = np.float32(MNIST_data['x_train'][:] )\n",
    "y_train = np.int32(np.array(MNIST_data['y_train'][:,0]))\n",
    "x_test = np.float32( MNIST_data['x_test'][:] )\n",
    "y_test = np.int32( np.array( MNIST_data['y_test'][:,0] ) )\n",
    "MNIST_data.close()\n",
    "#x_train = x_train.reshape((60000,28,28))\n",
    "#y_train = x_train.reshape((60000,28,28))\n",
    "#x_test = x_train.reshape((60000,28,28))\n",
    "#y_test = x_train.reshape((60000,28,28))\n",
    "\n",
    "#plt.imshow(x_train[0,], cmap=\"gray\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Implementation of stochastic gradient descent algorithm\n",
    "#number of inputs\n",
    "num_inputs = 28*28\n",
    "#number of hidden units\n",
    "num_h = 100\n",
    "#number of outputs\n",
    "num_outputs = 10\n",
    "d = 28\n",
    "kx = 3\n",
    "ky = 3\n",
    "num_channel = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 26)\n"
     ]
    }
   ],
   "source": [
    "#initialize parameters\n",
    "model = {}\n",
    "model['W'] = np.random.randn(num_outputs,d - ky+1,d-kx+1)*0.01\n",
    "#model['W'] = np.random.randn(num_outputs,d - ky+1,d-kx+1,num_channel)*0.01\n",
    "#/ np.sqrt(num_inputs)\n",
    "model['b'] = np.zeros((num_outputs,1))\n",
    "\n",
    "model['k'] = np.random.randn(3,3) * 0.01\n",
    "#model['k'] = np.random.randn(3,3,num_channel) * 0.01\n",
    "#/ np.sqrt(d)\n",
    "model_grads = copy.deepcopy(model)\n",
    "print(model['W'][1,:,:].shape)\n",
    "\n",
    "\n",
    "def conv_single(x,k,i,j):\n",
    "    out = 0\n",
    "    for m in range(ky-1):\n",
    "        for n in range(kx - 1):\n",
    "            out += k[m,n]*x[i +m,j+n]\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def conv(x,k,d,ky,kx):\n",
    "    output = np.zeros((d-ky+1,d-kx+1))\n",
    "    for i in range(d-ky+1):\n",
    "        for j in range(d-kx+1):\n",
    "            output[i,j] = conv_single(x,k,i,j)\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_function(z):\n",
    "    ZZ = np.exp(z)/np.sum(np.exp(z))\n",
    "    return ZZ\n",
    "\n",
    "def relu(z):\n",
    "    return z * (z > 0)\n",
    "\n",
    "def relu_back(z):\n",
    "    return (z>0)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return np.exp(z)/(1+np.exp(z))\n",
    "\n",
    "#derivative of sigmoid\n",
    "def sigmoid_back(z):\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s * (1-s)\n",
    "\n",
    "def forward(x,y,model):\n",
    "    \n",
    "    x = x.reshape((784,1))\n",
    "    x = x.reshape((28,28))\n",
    "    #model['H'] = np.zeros((d - ky+1,d-kx+1,num_channel))\n",
    "    #model['Z'] = np.zeros((d - ky+1,d-kx+1,num_channel))\n",
    "    #Z = np.dot(model['W1'], x) + model['b1']\n",
    "    #Z = conv(x,model['k'],d,ky,kx)\n",
    "    \n",
    "    #for p in range(num_channel):\n",
    "    #Z = conv(x,model['k'][:,:,p],d,ky,kx)\n",
    "    Z = scipy.signal.correlate2d(x,model['k'],mode ='valid')\n",
    "    #print(Z.shape)\n",
    "    #print x.shape, model['k'].shape\n",
    "    #Z = scipy.signal.convolve2d(x, np.rot90(model['k'], 2), 'valid')\n",
    "    \n",
    "    #print(Z.shape)\n",
    "    H = relu(Z)\n",
    "    model['H'] = H\n",
    "    model['Z'] = Z\n",
    "    \n",
    "    Utemp = np.dot(model['W'].reshape(num_outputs,np.prod(model['H'].shape)),\n",
    "                   model['H'].reshape(np.prod(model['H'].shape)))\n",
    "    U = Utemp.reshape((num_outputs,1)) + model['b']\n",
    "    #U = np.tensordot(model['W'],model['H'],)\n",
    "    #for i in range(10):\n",
    "    #    tempw = model['W'][i,:,:]\n",
    "    #    print(np.dot(tempw,H))\n",
    "    #    U[i] = np.dot(tempw,H) + model['b'][i]\n",
    "        \n",
    "    p = softmax_function(U)\n",
    "    return p\n",
    "    \n",
    "def backward(x,y,p, model, model_grads):\n",
    "    x = x.reshape((784,1))\n",
    "    x = x.reshape((28,28))\n",
    "    \n",
    "    dU = -1.0*p\n",
    "    dU[y] = dU[y] + 1.0\n",
    "    db = dU\n",
    "    \n",
    "    #dW = np.zeros((10,d - ky+1,d-kx+1))\n",
    "    #for k in range(10):\n",
    "    #    dW[k,:,:] = dU[k]*model['H']\n",
    "    #dw = dU* model['H']\n",
    "    #dW = np.dot(dU,model['H'])    \n",
    "    delta = np.dot(model['W'].reshape(num_outputs,np.prod(model['H'].shape)).T,dU)\n",
    "    delta = delta.reshape((26,26,num_channel))\n",
    "    sigmaprime = relu_back(model['Z'])\n",
    "   \n",
    "    #dK = np.zeros((3,3,num_channel))\n",
    "    #for p in range(num_channel):\n",
    "    #    multi = np.multiply(delta[:,:,p],sigmaprime[:,:,p])\n",
    "    #    dK[:,:,p]= conv(x,multi,d,multi.shape[0],multi.shape[1])\n",
    "    \n",
    "    #print(delta.shape)\n",
    "    #print(db1.shape)\n",
    "    #print(sigmaprime.shape)\n",
    "    H = model['H']\n",
    "    #delta = np.dot(dU, model['W'].reshape(model['W'].shape[0],np.prod(H.shape))).reshape(H.shape)\n",
    "    #actv_grad = (H>0).astype(float)\n",
    "    multi = np.multiply(delta.reshape((26,26)),sigmaprime)\n",
    "    #print(multi.shape)\n",
    "    #multi = np.multiply(delta, actv_grad)\n",
    "    #dK = conv(x,multi,d,multi.shape[0],multi.shape[1])\n",
    "    dK = scipy.signal.correlate2d(x,multi,mode = 'valid')\n",
    "    \n",
    "    model_grads['W'] = np.dot(dU.reshape(num_outputs,1), H.reshape(np.prod(H.shape),1).T).reshape(model_grads['W'].shape)\n",
    "    \n",
    "   \n",
    "    \n",
    "    #model_grads['K'] = convolve(x,np.multiply(delta, actv_grad))\n",
    "    \n",
    "    \n",
    "    #model_grads['W'] = dW  \n",
    "    model_grads['b'] = db\n",
    "    model_grads['k'] = dK\n",
    "   \n",
    "    return model_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88985\n",
      "0.9118\n",
      "0.9177166666666666\n",
      "0.9198333333333333\n",
      "0.9213333333333333\n",
      "0.9241166666666667\n",
      "0.9214166666666667\n",
      "0.92325\n",
      "0.92215\n",
      "0.9247333333333333\n",
      "78.79336667060852\n"
     ]
    }
   ],
   "source": [
    "#timer\n",
    "import time\n",
    "time1 = time.time()\n",
    "LR = .01\n",
    "num_epochs = 10\n",
    "\n",
    "for epochs in range(num_epochs):\n",
    "    #Learning rate schedule\n",
    "    #if (epochs > 5):\n",
    "    #    LR = 0.001\n",
    "    #if (epochs > 10):\n",
    "    #    LR = 0.0001\n",
    "    #if (epochs > 15):\n",
    "    #    LR = 0.00001\n",
    "    LR = 0.01\n",
    "    total_correct = 0\n",
    "    for n in range( len(x_train)):\n",
    "        n_random = randint(0,len(x_train)-1 )\n",
    "        y = y_train[n_random]\n",
    "        x = x_train[n_random][:]\n",
    "        p = forward(x, y, model)\n",
    "        prediction = np.argmax(p)\n",
    "        if (prediction == y):\n",
    "            total_correct += 1\n",
    "        model_grads = backward(x,y,p, model, model_grads)\n",
    "        \n",
    "        #update parameter\n",
    "        model['W'] = model['W'] + LR*model_grads['W']\n",
    "        model['b'] = model['b'] + LR*model_grads['b']\n",
    "        model['k'] = model['k'] + LR*model_grads['k']\n",
    "        #model['b2'] = model['b2'] + LR*model_grads['b2']\n",
    "        \n",
    "    print(total_correct/np.float(len(x_train) ) )\n",
    "time2 = time.time()\n",
    "print(time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "#test data\n",
    "total_correct = 0\n",
    "for n in range( len(x_test)):\n",
    "    y = y_test[n]\n",
    "    x = x_test[n][:]\n",
    "    p = forward(x, y, model)\n",
    "    prediction = np.argmax(p)\n",
    "    if (prediction == y):\n",
    "        total_correct += 1\n",
    "        \n",
    "#accuracy on test set\n",
    "print(total_correct/np.float(len(x_test) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
